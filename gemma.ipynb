{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1HDSyuTo8IkIHTwj6z4IO-39PanFzYay9","timestamp":1768898124137},{"file_id":"1oSeei1BtxcwKNInbj59HldE8in4wGOGK","timestamp":1768852730528},{"file_id":"1w5bpQK4raPH_MUPSTWHC0X_SqaEjHu60","timestamp":1768848323659}],"mount_file_id":"1HDSyuTo8IkIHTwj6z4IO-39PanFzYay9","authorship_tag":"ABX9TyMFVOAG0dj9jFvzpXx9foRl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b41d44e844c94b1e8420a094e71f67e5":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_73e591d204094af59d9ecc1d55d40897"}},"66db290a524d4c498b971652719fd336":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c7f10d794d54316ab0ffb6c2cc9c856","placeholder":"​","style":"IPY_MODEL_7cc9540622b244a396e091a8441290d4","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"46d4d0b276014070bca04ff66b409114":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_9b30b806015d4ec19196a17abfbb4a34","placeholder":"​","style":"IPY_MODEL_dde3557ab3e841c7a9e68681f51c72a5","value":""}},"92330c888c0748e7ae045821f6ff12b7":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_6b8f14ee02ae449680dd33622d0bfdc6","style":"IPY_MODEL_d5a9b72530fe4503974c40da3c773c92","value":true}},"833c87f27adc44cfaedea95750708058":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_af89749f43e14c22aec87d1151dd864c","style":"IPY_MODEL_bdfe6383ad0d445abd4f38165f6f3920","tooltip":""}},"f0b996220e83462fa8cb602bec34c6bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f87a32109f364179932d503b569b899b","placeholder":"​","style":"IPY_MODEL_ed915c22e7a747c9adeb872f20213446","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"73e591d204094af59d9ecc1d55d40897":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"5c7f10d794d54316ab0ffb6c2cc9c856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cc9540622b244a396e091a8441290d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b30b806015d4ec19196a17abfbb4a34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde3557ab3e841c7a9e68681f51c72a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b8f14ee02ae449680dd33622d0bfdc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5a9b72530fe4503974c40da3c773c92":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af89749f43e14c22aec87d1151dd864c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bdfe6383ad0d445abd4f38165f6f3920":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"f87a32109f364179932d503b569b899b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed915c22e7a747c9adeb872f20213446":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b5ef48550b9948f298e3e291770b5f0b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81e159ff8d5a46fa89d5cf77ed7de983","placeholder":"​","style":"IPY_MODEL_9c4d86a9cf62474193c781601bbe0899","value":"Connecting..."}},"81e159ff8d5a46fa89d5cf77ed7de983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c4d86a9cf62474193c781601bbe0899":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qi4fgVrlUJwn","executionInfo":{"status":"ok","timestamp":1768894745272,"user_tz":-330,"elapsed":2000,"user":{"displayName":"1065 Shriganga A G","userId":"11943577731829294603"}},"outputId":"93c372d8-d8a8-432d-eeb7-1a243481e809"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","True\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["from huggingface_hub import login\n","\n","login()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["b41d44e844c94b1e8420a094e71f67e5","66db290a524d4c498b971652719fd336","46d4d0b276014070bca04ff66b409114","92330c888c0748e7ae045821f6ff12b7","833c87f27adc44cfaedea95750708058","f0b996220e83462fa8cb602bec34c6bc","73e591d204094af59d9ecc1d55d40897","5c7f10d794d54316ab0ffb6c2cc9c856","7cc9540622b244a396e091a8441290d4","9b30b806015d4ec19196a17abfbb4a34","dde3557ab3e841c7a9e68681f51c72a5","6b8f14ee02ae449680dd33622d0bfdc6","d5a9b72530fe4503974c40da3c773c92","af89749f43e14c22aec87d1151dd864c","bdfe6383ad0d445abd4f38165f6f3920","f87a32109f364179932d503b569b899b","ed915c22e7a747c9adeb872f20213446","b5ef48550b9948f298e3e291770b5f0b","81e159ff8d5a46fa89d5cf77ed7de983","9c4d86a9cf62474193c781601bbe0899"]},"id":"tcR0OIv4hLT8","executionInfo":{"status":"ok","timestamp":1768894760304,"user_tz":-330,"elapsed":2385,"user":{"displayName":"1065 Shriganga A G","userId":"11943577731829294603"}},"outputId":"c1d71612-078b-4baa-d985-717c3dfe8a44"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b41d44e844c94b1e8420a094e71f67e5"}},"metadata":{}}]},{"cell_type":"markdown","source":["Tokenization"],"metadata":{"id":"2hjk9hq2j5uN"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import html\n","import warnings\n","import os\n","import torch\n","from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","\n","# -------------------------------\n","# Suppress warnings\n","# -------------------------------\n","warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n","\n","# -------------------------------\n","# Paths\n","# -------------------------------\n","DATA_PATH = \"/content/drive/MyDrive/NewsSumm Dataset.xlsx\"\n","SAVE_DIR  = \"/content/drive/MyDrive/tokenized_gemma_batches\"\n","\n","TRAIN_DIR = os.path.join(SAVE_DIR, \"train\")\n","TEST_DIR  = os.path.join(SAVE_DIR, \"test\")\n","\n","os.makedirs(TRAIN_DIR, exist_ok=True)\n","os.makedirs(TEST_DIR, exist_ok=True)\n","\n","# -------------------------------\n","# Load dataset\n","# -------------------------------\n","df = pd.read_excel(DATA_PATH)\n","df = df.dropna(subset=[\"human_summary\"])\n","print(\"Rows after cleaning:\", len(df))\n","\n","# -------------------------------\n","# Resample to 15,000 rows\n","# -------------------------------\n","df = df.sample(n=15000, random_state=42)\n","print(\"Rows after resampling:\", len(df))\n","\n","# -------------------------------\n","# Clean text\n","# -------------------------------\n","def clean_text(text):\n","    if not isinstance(text, str):\n","        return \"\"\n","    text = BeautifulSoup(text, \"html.parser\").get_text(\" \")\n","    text = html.unescape(text)\n","    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n","    text = re.sub(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \"\", text)\n","    text = re.sub(r\"\\+?\\d[\\d\\s\\-]{8,}\\d\", \"\", text)\n","    text = re.sub(r\"\\s+\", \" \", text).strip()\n","    return text\n","\n","df[\"human_summary\"] = df[\"human_summary\"].apply(clean_text)\n","\n","# -------------------------------\n","# Train–test split (80/20)\n","# -------------------------------\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","print(\"Train rows:\", len(train_df))\n","print(\"Test rows:\", len(test_df))\n","\n","train_texts = train_df[\"human_summary\"].astype(str).tolist()\n","test_texts  = test_df[\"human_summary\"].astype(str).tolist()\n","\n","# -------------------------------\n","# Load Gemma tokenizer\n","# -------------------------------\n","MODEL_NAME = \"google/gemma-2b\"   # or: google/gemma-7b\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","# Gemma has no pad token → use EOS token\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# -------------------------------\n","# Tokenization settings\n","# -------------------------------\n","BATCH_SIZE = 4\n","MAX_LEN = 128\n","\n","def tokenize_and_save(texts, out_dir, split_name):\n","    print(f\"\\nTokenizing {split_name} set...\")\n","\n","    batch_id = 0\n","\n","    for i in range(0, len(texts), BATCH_SIZE):\n","        batch_texts = texts[i:i+BATCH_SIZE]\n","\n","        encoded = tokenizer(\n","            batch_texts,\n","            truncation=True,\n","            padding=\"max_length\",\n","            max_length=MAX_LEN,\n","            return_tensors=\"pt\"\n","        )\n","\n","        input_ids = encoded[\"input_ids\"]\n","        attention_mask = encoded[\"attention_mask\"]\n","\n","        batch_data = {\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"labels\": input_ids.clone()\n","        }\n","\n","        save_path = os.path.join(out_dir, f\"batch_{batch_id}.pt\")\n","        torch.save(batch_data, save_path)\n","\n","        if batch_id % 50 == 0:\n","            print(f\"{split_name}: saved batch {batch_id}\")\n","\n","        batch_id += 1\n","\n","    print(f\"{split_name} tokenization done. Total batches: {batch_id}\")\n","\n","# -------------------------------\n","# Run tokenization\n","# -------------------------------\n","tokenize_and_save(train_texts, TRAIN_DIR, \"TRAIN\")\n","tokenize_and_save(test_texts, TEST_DIR, \"TEST\")\n","\n","print(\"\\nGemma summary-only batchwise tokenization completed \")\n"],"metadata":{"id":"GwNDeT90USyx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y torch torchvision torchaudio bitsandbytes\n","!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n","!pip install -U bitsandbytes transformers peft accelerate rouge-score\n"],"metadata":{"id":"hWDWy1sWijf6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["model training"],"metadata":{"id":"Q-U-dNZPkBu9"}},{"cell_type":"code","source":["import os, torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from peft import LoraConfig, get_peft_model\n","from bitsandbytes.optim import AdamW8bit\n","\n","MODEL_NAME = \"google/gemma-2b\"\n","TRAIN_DIR = \"/content/drive/MyDrive/tokenized_gemma_batches/train/\"\n","SAVE_DIR = \"/content/drive/MyDrive/gemma2b_qlora\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    quantization_config=bnb_config,\n","    device_map={\"\": 0}\n",")\n","\n","lora_config = LoraConfig(\n","    r=8,\n","    lora_alpha=16,\n","    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"],\n","    lora_dropout=0.05,\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","model.train()\n","\n","optim = AdamW8bit(model.parameters(), lr=2e-4)\n","\n","files = sorted([f for f in os.listdir(TRAIN_DIR) if f.endswith(\".pt\")])\n","\n","for i, fname in enumerate(files, 1):\n","    batch = torch.load(os.path.join(TRAIN_DIR, fname))\n","\n","    out = model(\n","        input_ids=batch[\"input_ids\"].cuda(),\n","        attention_mask=batch[\"attention_mask\"].cuda(),\n","        labels=batch[\"labels\"].cuda()\n","    )\n","\n","    out.loss.backward()\n","    optim.step()\n","    optim.zero_grad()\n","\n","    if i % 50 == 0:\n","        print(\"batch\", i, \"loss\", out.loss.item())\n","\n","model.save_pretrained(SAVE_DIR)\n","tokenizer.save_pretrained(SAVE_DIR)\n","\n","print(\"QLoRA training finished \")\n"],"metadata":{"id":"-GAA9mQccCw8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["model evaluation"],"metadata":{"id":"1oyT_PFSkGVr"}},{"cell_type":"code","source":["import os\n","import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","from peft import PeftModel\n","from rouge_score import rouge_scorer\n","\n","# --------------------\n","# Paths\n","# --------------------\n","TEST_DIR = \"/content/drive/MyDrive/tokenized_gemma_batches/test/\"\n","BASE_MODEL = \"google/gemma-2b\"\n","LORA_DIR = \"/content/drive/MyDrive/gemma2b_qlora\"\n","\n","# --------------------\n","# Device\n","# --------------------\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","# --------------------\n","# Load tokenizer\n","# --------------------\n","tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"left\"\n","\n","# --------------------\n","# Load base model in 4-bit\n","# --------------------\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16\n",")\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    BASE_MODEL,\n","    quantization_config=bnb_config,\n","    device_map={\"\": 0}\n",")\n","\n","# --------------------\n","# Load LoRA adapter\n","# --------------------\n","model = PeftModel.from_pretrained(base_model, LORA_DIR)\n","model.eval()\n","\n","# --------------------\n","# ROUGE scorer\n","# --------------------\n","scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n","\n","r1 = r2 = rl = 0.0\n","r11 = r21 = rl1 = 0.0\n","count = 0\n","\n","files = sorted([f for f in os.listdir(TEST_DIR) if f.endswith(\".pt\")])\n","\n","# --------------------\n","# Evaluation loop\n","# --------------------\n","for fname in files:\n","\n","    batch = torch.load(os.path.join(TEST_DIR, fname))\n","\n","    input_ids = batch[\"input_ids\"].to(device)\n","    attention_mask = batch[\"attention_mask\"].to(device)\n","    labels = batch[\"labels\"]\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            max_new_tokens=50\n","        )\n","\n","    gen_only = outputs[:, input_ids.shape[1]:]\n","    preds = tokenizer.batch_decode(gen_only, skip_special_tokens=True)\n","    refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    for pred, ref in zip(preds, refs):\n","        scores = scorer.score(ref, pred)\n","\n","        r1 += scores[\"rouge1\"].fmeasure\n","        r2 += scores[\"rouge2\"].fmeasure\n","        rl += scores[\"rougeL\"].fmeasure\n","\n","        r11 += scores[\"rouge1\"].precision\n","        r21 += scores[\"rouge2\"].precision\n","        rl1 += scores[\"rougeL\"].precision\n","\n","        count += 1\n","\n","# --------------------\n","# Final results\n","# --------------------\n","print(\"\\nROUGE RESULTS\")\n","print(\"ROUGE-1-f1_score:\", round(r1 / count, 4))\n","print(\"ROUGE-2-f1_score:\", round(r2 / count, 4))\n","print(\"ROUGE-L-f1_score:\", round(rl / count, 4))\n","print(\"ROUGE-1-precision:\", round(r11 / count, 4))\n","print(\"ROUGE-2-precision:\", round(r21 / count, 4))\n","print(\"ROUGE-L-precision:\", round(rl1 / count, 4))\n"],"metadata":{"id":"KCKfdKb10iAi"},"execution_count":null,"outputs":[]}]}